{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series Toy Model\n",
    "\n",
    "## Competitive Lotka-Volterra equations\n",
    "\n",
    "We are going to define a simple time series model based on the [competive Lotka-Volterra equations](https://en.wikipedia.org/wiki/Competitive_Lotka%E2%80%93Volterra_equations),\n",
    "\n",
    "$$\n",
    "{\\frac  {d x_{i}}{dt}} = \n",
    "r_{i}x_{i} \\left(1 - {\\frac{\\sum _{{j=1}}^{N} A _{{ij}}x_{j}}{K}}\\right)\n",
    "$$,\n",
    "\n",
    "where $x_i$ is the number of species $i$ present, $r_i$ is the inherent growth rate, $K$ is the carrying capacity, $A_{ij}$ is the interaction matrix between the different species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def lotka_volterra(x, t, r, A, K):\n",
    "    return x * r * (1 - A.dot(x)/K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classic instance of the equations are shown below, demonstrating chaotic behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "colors = plt.rcParams[\"axes.prop_cycle\"].by_key()['color']\n",
    "species_colors = colors[:4]\n",
    "\n",
    "r = np.array([1, 0.72, 1.53, 1.27])\n",
    "A = np.array([\n",
    "    [1.  , 1.09, 1.52, 0.  ],\n",
    "    [0.  , 1.  , 0.44, 1.36],\n",
    "    [2.33, 0.  , 1.  , 0.47],\n",
    "    [1.21, 0.51, 0.35, 1.  ]])\n",
    "K = 1e6\n",
    "\n",
    "x0 = (np.random.exponential(0.1, 4) + 0.005)*K\n",
    "ts = np.linspace(0, 100, 2**10)\n",
    "xt = odeint(lotka_volterra, x0, ts, args=(r, A, K))\n",
    "\n",
    "for i, color in enumerate(species_colors):\n",
    "    plt.plot(ts, xt[:, i], color=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic  model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further generalise these Lotka-Volterra equations to incorporate a stochastic element, where we split the equation above into a [birth-death process](https://en.wikipedia.org/wiki/Birth%E2%80%93death_process), where we define the growth rate of the population,\n",
    "$$ \n",
    "\\lambda_{x_i \\rightarrow x_i + 1} = r_{i}x_{i},\n",
    "$$\n",
    "and death rate,\n",
    "$$ \n",
    "\\lambda_{x_i \\rightarrow x_i - 1} = \n",
    "r_{i}x_{i}\\frac{\\sum _{{j=1}}^{N} A _{{ij}}x_{j}}{K}.\n",
    "$$\n",
    "These birth-death processes can be simulated in a variety ways, in this case we will use the [tau-leaping algorithm](https://en.wikipedia.org/wiki/Tau-leaping) which assumes that over a short time step, $\\Delta t$, the magnitude of the populations $x_i$ does not change significantly, so the number of birth and death processes during that period can be modelled as as Poisson process,\n",
    "\n",
    "$$\n",
    "\\Delta_{x_i +} \\sim \\text{Pois}(\\lambda_{x_i \\rightarrow x_i + 1} \\Delta t),$$\n",
    "$$\n",
    "\\Delta_{x_i -} \\sim \\text{Pois}(\\lambda_{x_i \\rightarrow x_i - 1} \\Delta t),$$\n",
    "$$\n",
    "\\Delta_{x_i} = \\Delta_{x_i +} - \\Delta_{x_i -},\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import poisson\n",
    "\n",
    "def LV_birthdeath(x, t, r, A, K):\n",
    "    xr = x * r\n",
    "    return xr, xr * A.dot(x)/K\n",
    "\n",
    "def tau_leaping(func, x0, ts, args=()):\n",
    "    \"\"\"\n",
    "    Simulate a birth death process using the tau leaping algorithm\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    func: callable(x, ts, ...)\n",
    "        Computes the birth and death rate of the process, must return a 2-tuple\n",
    "        where the 1st element is the birth rate and the 2nd element is the death rate\n",
    "        \n",
    "    x0: array\n",
    "        The initial value of x\n",
    "        \n",
    "    t: array\n",
    "        A sequence of time points for which to solve for y. The initial value point \n",
    "        should be the first element of this sequence. This sequence must be monotonically \n",
    "        increasing or monotonically decreasing; repeated values are allowed.\n",
    "\n",
    "    args: tuple, optional\n",
    "        Extra arguments to pass to function.\n",
    "    \"\"\"\n",
    "    xs = np.zeros(np.shape(ts) + np.shape(x0))\n",
    "    xs[0, :] = x0\n",
    "    delta_t = np.diff(ts)\n",
    "    for i, (t, dt) in enumerate(zip(ts[1:], delta_t)):\n",
    "        x = xs[i]\n",
    "        birthrate, deathrate = func(x, t, *args)\n",
    "        deltax = poisson(birthrate*dt) - poisson(deathrate*dt)                                    \n",
    "        xs[i + 1] = x + deltax\n",
    "        \n",
    "    return xs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repeats = 30\n",
    "xs_stoch = np.empty((n_repeats, ) +  ts.shape + x0.shape)\n",
    "\n",
    "for i in range(n_repeats):\n",
    "    x0_stoch = np.random.poisson(x0)\n",
    "    xs_stoch[i] = tau_leaping(LV_birthdeath, x0_stoch, ts, args=(r, A, K))\n",
    "    \n",
    "xt_lo, xt_med, xt_hi = np.quantile(xs_stoch, [0.16,0.5,0.84], axis=0)\n",
    "\n",
    "for i, color in enumerate(species_colors):\n",
    "    plt.plot(ts, xt[:, i], color=color)\n",
    "    plt.plot(ts, xt_med[:, i], ls=':', color=color)\n",
    "    plt.fill_between(ts, xt_lo[:, i], xt_hi[:, i], color=color, alpha=0.5)\n",
    "    \n",
    "plt.ylim(0, xs_stoch.max() * 1.05)\n",
    "plt.xlim(ts[0], ts[-1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central limit approximation \n",
    "\n",
    "Performing inference on a birth-death process will be difficult as it is not possible to calculate the probability of observing a given state for a set of initial conditions except for when the maximum population size is very small, as the probabilistic master equation must be integrated, which has an $n_{species}^{\\max(\\sum x_i)}$ components.\n",
    "\n",
    "Likelihood free methods such as [approximate Bayesian computation (ABC)](https://en.wikipedia.org/wiki/Approximate_Bayesian_computation) could be used, however these methods are computationally expensive.\n",
    "\n",
    "The most computational efficient approach is to consider the ODE solution, \n",
    "$\\hat{\\mathbf{x}}(t) = (\\hat{x}_1(t), ..., \\hat{x}_n(t))$, to the process,\n",
    "\n",
    "$$K \\frac{d \\hat{x}_i(t)}{d t} = \\lambda_{x_i \\rightarrow x_i + 1} - \\lambda_{x_i \\rightarrow x_i - 1}$$,\n",
    "\n",
    "$$\\frac{d \\hat{x}_i(t)}{d t} = f(\\hat{x}_i(t))$$\n",
    "\n",
    "where $\\mathbf{f} = (f_1, ..., f_n)$ is the rate function of the ODE. In general there can be multiple types of birth-death process leading to larger or smaller  jumps.\n",
    "\n",
    "$$ K \\frac{d \\hat{x}_i(t)}{d t} = \\sum_{v} v \\lambda_{x_i \\rightarrow x_i + v}.$$\n",
    "\n",
    "\n",
    "This approach neglects stochastic fluctuations, and also cannot directly calculate the probability of observing a given state at a specific time.\n",
    "\n",
    "In this section we consider the [central limit approximation (CLA)](http://arxiv.org/abs/1804.08744) which models the distribution over number of species present at time $t_0$ as a normal distribution,\n",
    "\n",
    "$$ x_i(t) \\approx \\tilde{x}_i(t) \\sim K \\hat{x}_i(t) + K^{1/2} g_i(t),$$\n",
    "\n",
    "$$ \\mathbf{G}(t_0) = \\{g_1(t_0), ..., g_n(t_0)\\} \\sim \\mathcal{N}(\\mathbf{m}(t_0), \\mathbf{\\Sigma}(t_0)),$$\n",
    "\n",
    "which in turn makes $\\mathbf{G}$ a Gaussian process, \n",
    "\n",
    "$$ \\mathbf{g}(t) = \\{g_1(t), ..., g_n(t)\\} \\sim \\mathcal{GP}(\\mathbf{m}(t), \\mathbf{\\Sigma}(t)),$$\n",
    "\n",
    "The probability distribution of $\\mathbf{g}(t)$ is given by by the solution to the following differential equations,\n",
    "\n",
    "$$\\frac{d \\mathbf{m}(t)}{d t} = J_f(t) \\cdot \\mathbf{m}(t)\n",
    "$$\n",
    "\n",
    "$$\\frac{d \\mathbf{\\Sigma}(t)}{d t} =  \n",
    "J_f(t) \\cdot \\mathbf{\\Sigma}(t) + \\mathbf{\\Sigma}(t) \\cdot J^\\top_f(t) + W(t)\n",
    "$$\n",
    "where \n",
    "$$J_f(t) = \n",
    "\\left. \\nabla_{\\hat{\\mathbf{x}}} \\mathbf{f} \\right|_{\\hat{\\mathbf{x}} = \\hat{\\mathbf{x}}(t)}$$\n",
    "is the Jacobian of the ODE rate function, and\n",
    "$$W(t)_{i, i} = \n",
    "\\left(\\lambda_{x_i \\rightarrow x_i + 1} + \\lambda_{x_i \\rightarrow x_i - 1}\\right) \\frac{\\delta_{ij}}{K}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CLAint(func, x0, cov0, ts, args=()):\n",
    "    \"\"\"\n",
    "    Simulate a birth death process using the tau leaping algorithm\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    func: callable(x, ts, ...)\n",
    "        Computes the rate function and the Jacobian of the rate function\n",
    "        must return a tuple containing the value of the rate function as its first value\n",
    "        and the Jacobian as the second value\n",
    "        \n",
    "    x0: array\n",
    "        The initial value of x\n",
    "        \n",
    "    cov0: array\n",
    "        The initial covariance of x\n",
    "        \n",
    "    t: array\n",
    "        A sequence of time points for which to solve for y. The initial value point \n",
    "        should be the first element of this sequence. This sequence must be monotonically \n",
    "        increasing or monotonically decreasing; repeated values are allowed.\n",
    "\n",
    "    args: tuple, optional\n",
    "        Extra arguments to pass to function.\n",
    "    \"\"\"\n",
    "    xs = np.empty(np.shape(ts) + np.shape(x0))\n",
    "    xs[0, :] = x0\n",
    "    if np.ndim(cov0) == 1:\n",
    "        cov0 = np.diag(cov0)\n",
    "        \n",
    "    covs = np.empty(np.shape(ts) + np.shape(cov0))\n",
    "    covs[0, :, :] = cov0\n",
    "    \n",
    "    delta_t = np.diff(ts)\n",
    "    for i, (t, dt) in enumerate(zip(ts[1:], delta_t)):\n",
    "        x = xs[i]\n",
    "        cov = covs[i]\n",
    "        f, jac, W = func(x, t, *args)\n",
    "        xs[i + 1, :] = x + f * dt\n",
    "        covs[i + 1, :, :] = cov + jac.dot(cov) + cov.dot(jac.T) + W\n",
    "        \n",
    "    return xs, covs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lotka - Volterra CLA model\n",
    "\n",
    "Defining the Lotka-Volterra equations in this formalism we find,\n",
    "\n",
    "$$\n",
    "f_i(\\hat{\\mathbf{x}}) = \n",
    "{r_{i}\\hat{x}_{i}} \\left(1 - {{\\sum _{{j=1}}^{N} A _{{ij}}\\hat{x}_{j}}}\\right),\n",
    "$$\n",
    "with Jacobian,\n",
    "$$\n",
    "J_f(\\hat{\\mathbf{x}})_{i, j} = \n",
    "\\frac{r_{i}}{K}\\left(1 - {{\\sum _{{k=1}}^{N} A _{{ik}}\\hat{x}_{k}}} \\right)  \\delta_{i, j}\n",
    "- \\frac{r_{i} \\hat{x}_i A_{{i, j}}}{K},\n",
    "$$\n",
    "and \n",
    "$$\n",
    "W(\\hat{\\mathbf{x}})_{i, j} = \\frac{r_{i}\\hat{x}_{i}}{K}\n",
    "\\left(1 + {{\\sum _{{j=1}}^{N} A _{{ij}}\\hat{x}_{j}}}\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LV_CLA(x, t, r, A, K):\n",
    "    rx = x * r\n",
    "    Ax = A.dot(x)\n",
    "    d = r * (1 - Ax)\n",
    "    f = d * x\n",
    "    jac = - rx[:, None] * A \n",
    "    jac[np.diag_indices(4)] += d\n",
    "    W = rx * (1 + Ax)\n",
    "    return f, jac/K, W/K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov0 = np.diag(x0 * K**-2)\n",
    "x_cla, cov_cla = CLAint(LV_CLA, x0 / K, cov0, ts, args=(r, A, K))\n",
    "x_cla_std = cov_cla[(slice(None),) + np.diag_indices(4)]**0.5\n",
    "\n",
    "for i, color in enumerate(species_colors):\n",
    "    plt.plot(ts, x_cla[:, i], ls=':', color=color)\n",
    "    plt.fill_between(ts, x_cla[:, i] - x_cla_std[:, i], \n",
    "                     x_cla[:, i] + x_cla_std[:, i], color=color, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, color in enumerate(species_colors):\n",
    "    plt.plot(ts, xt_med[:, i], ls=':', color=color)\n",
    "    plt.fill_between(ts, xt_lo[:, i], xt_hi[:, i], color=color, alpha=0.5)\n",
    "    \n",
    "plt.ylim(0, xs_stoch.max() * 1.05)\n",
    "plt.xlim(ts[0], ts[-1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Model\n",
    "\n",
    "Frequently we do not have direct access to the size of the populations and when we sample from the population we do not even from which species our sample came from. Instead we observe the properties of a set of individuals sampled from the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.path as path\n",
    "from IPython.display import HTML\n",
    "\n",
    "class Histogram(object):\n",
    "    \"\"\"\n",
    "    updateable histogram for matplotlib animations\n",
    "    \"\"\"\n",
    "    def __init__(self, a, bins=10, quantiles=None, range=None, density=None, weights=None, \n",
    "                 plot=True, **kwargs):\n",
    "        self.patch = None\n",
    "        self.bins = 10\n",
    "        \n",
    "        self._hist_kwargs = dict(range=range, density=density, weights=weights)\n",
    "        self.hist, self.bins = self.histogram(a, bins=bins, quantiles=quantiles)\n",
    "        self.ax = None\n",
    "\n",
    "        self._initialize_verts()\n",
    "        if plot:\n",
    "            self.plot(**kwargs)\n",
    "            \n",
    "    def update_lims(self):\n",
    "        ax = self.ax\n",
    "        xlim = ax.get_xlim()\n",
    "        ax.set_xlim(min(xlim[0], self.bins[0]), max(xlim[1], self.bins[-1]))\n",
    "        ylim = ax.get_ylim()\n",
    "        ax.set_ylim(min(xlim[0], 0), max(ylim[1], self.hist.max()))\n",
    "            \n",
    "    def plot(self, ax=None, **kwargs):\n",
    "        patch = self._make_patch(**kwargs)\n",
    "        if ax is None:\n",
    "            ax = plt.gca()\n",
    "        \n",
    "        ax.add_patch(patch)\n",
    "        self.ax = ax\n",
    "        self.update_lims()\n",
    "        return [patch]\n",
    "        \n",
    "    def histogram(self, a, bins=None, quantiles=None, **kwargs):\n",
    "        if bins is None:\n",
    "            bins = self.bins\n",
    "            \n",
    "        if quantiles is not None:\n",
    "            if isinstance(quantiles, int):\n",
    "                bins = np.quantile(a, np.linspace(0, 1, quantiles))\n",
    "            else:\n",
    "                bins = np.quantile(a, quantiles)\n",
    "        \n",
    "        kwargs.update(self._hist_kwargs)\n",
    "        return np.histogram(a, bins=bins, **kwargs)\n",
    "    \n",
    "    def update_data(self, a, update_lims=True, **kwargs):\n",
    "        self.hist, _ = self.histogram(a, **kwargs)\n",
    "        self._set_verts()\n",
    "        if update_lims:\n",
    "            self.update_lims()\n",
    "        return [self.patch]\n",
    "        \n",
    "    def _initialize_verts(self):\n",
    "        # get the corners of the rectangles for the histogram\n",
    "        nrects = self.bins.size -1\n",
    "        nverts = nrects * (1 + 3 + 1)\n",
    "        verts = np.zeros((nverts, 2))\n",
    "        codes = np.ones(nverts, int) * path.Path.LINETO\n",
    "        codes[0::5] = path.Path.MOVETO\n",
    "        codes[4::5] = path.Path.CLOSEPOLY\n",
    "        \n",
    "        self.codes = codes\n",
    "        self.verts = verts\n",
    "        self._set_verts()\n",
    "        \n",
    "    def _set_verts(self, top=None, bottom=None, left=None, right=None):\n",
    "        if top is None:\n",
    "            top = self.hist\n",
    "        if left is None:\n",
    "            left = self.bins[:-1]\n",
    "        if right is None:\n",
    "            right = self.bins[1:]\n",
    "        if bottom is None:\n",
    "            bottom = np.zeros(len(left))\n",
    "\n",
    "        verts = self.verts\n",
    "        verts[0::5, 0] = left\n",
    "        verts[0::5, 1] = bottom\n",
    "        verts[1::5, 0] = left\n",
    "        verts[1::5, 1] = top\n",
    "        verts[2::5, 0] = right\n",
    "        verts[2::5, 1] = top\n",
    "        verts[3::5, 0] = right\n",
    "        verts[3::5, 1] = bottom\n",
    "        \n",
    "    def _make_patch(self, **kwargs):\n",
    "        self.patch = patches.PathPatch(path.Path(self.verts, self.codes), **kwargs)\n",
    "        return self.patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume that we can measure 3 properties associated with each species. In this case we assume that the properties of each species are distributed normally,\n",
    "\n",
    "$$y_{i,j} \\sim \\mathcal{N}(\\mu_{i, j}, \\sigma_{i, j}),$$\n",
    "\n",
    "see below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "n_prop = 3\n",
    "y_mean = stats.uniform.rvs(size=(4, n_prop)) * 2 - 1\n",
    "y_std = stats.invgamma.rvs(70., size=(4, n_prop)) ** 0.5\n",
    "y_dists = [stats.norm(loc=mu, scale=std) \n",
    "                for mu, std in zip(y_mean, y_std)]\n",
    "\n",
    "f, axes = plt.subplots(3, sharex=True)\n",
    "\n",
    "ys = np.linspace(-2, 2, 1000)\n",
    "pdf = np.zeros(ys.shape + (n_prop,))\n",
    "for dist, color in zip(y_dists, species_colors):\n",
    "    species_pdf = dist.pdf(ys[:, None])\n",
    "    pdf += species_pdf\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.plot(ys, species_pdf[:, i], color=color, zorder=10)\n",
    "        \n",
    "for i, ax in enumerate(axes):\n",
    "    ax.plot(ys, pdf[:, i], color='k', ls=':', zorder=-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we sample from the population we only observe the relative proportions of the species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_fracs = xt / xt.sum(1, keepdims=True)\n",
    "\n",
    "plt.plot(ts, rel_fracs)\n",
    "plt.ylabel(\"relative proportions\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if we consider time point t=50 and draw a sample from that time point we can observe the distribution of property values from our sample,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(6, 6), sharex=True)\n",
    "\n",
    "lim = (-1.5, 1.5)\n",
    "\n",
    "n_samples = 10000\n",
    "\n",
    "rel_frac = rel_fracs[ts.searchsorted(50)]\n",
    "\n",
    "n_species_sampled = np.random.multinomial(n_samples, rel_frac)\n",
    "sample = np.concatenate(\n",
    "    [dist.rvs(size=(n, n_prop)) for dist, n in zip(y_dists, n_species_sampled)])\n",
    "\n",
    "hist2d_kws = dict(bins=30, range=[lim]*2, cmap='Purples')\n",
    "for i in range(n_prop):\n",
    "    Histogram(sample[:, i], bins=30, density=True, \n",
    "              color=colors[4], alpha=0.5, ax=axes[i, i])\n",
    "    axes[i, i].set_xlim(*lim)\n",
    "    axes[i, i].set_ylim(0, 2)\n",
    "    \n",
    "    axes[-1, i].set_xlabel(\"property {:d}\".format(i))\n",
    "    axes[i, 0].set_ylabel(\"property {:d}\".format(i))\n",
    "    \n",
    "    for j in range(i):\n",
    "        Z, x, y = np.histogram2d(sample[:, j], sample[:, i], bins=30, range=[lim]*2)\n",
    "        X, Y = np.meshgrid(x[:-1], y[:-1])\n",
    "        axes[j, i].contour(X, Y, Z)#, cmap='Purples')\n",
    "        axes[i, j].scatter(sample[:, j], sample[:, i], \n",
    "                           marker='+', color=colors[6], alpha=0.1)\n",
    "        axes[i, j].set_xlim(*lim)\n",
    "        axes[i, j].set_ylim(*lim)\n",
    "        \n",
    "for ax in axes.flatten():\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0., wspace=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5000\n",
    "bins = np.linspace(-1.5, 1.5, 100)\n",
    "\n",
    "fig, axes = plt.subplots(3, sharex=True)\n",
    "\n",
    "ys = bins\n",
    "pdf = np.zeros(ys.shape + (n_prop,))\n",
    "\n",
    "lines = [[] for _ in y_dists]\n",
    "totals = []\n",
    "\n",
    "for dist, f, color, ls in zip(y_dists, rel_frac, species_colors, lines):\n",
    "    species_pdf = f * dist.pdf(ys[:, None])\n",
    "    pdf += species_pdf\n",
    "    for i, ax in enumerate(axes):\n",
    "        ls.extend(ax.plot(ys, species_pdf[:, i], color=color, zorder=10))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    totals.extend(ax.plot(ys, pdf[:, i], color='k', ls=':', zorder=-10))\n",
    "\n",
    "histograms = [\n",
    "    Histogram(sample[:, i], bins=bins, density=True, \n",
    "              color=colors[4], alpha=0.5, ax=ax) for i, ax in enumerate(axes)]\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.set_ylim(0, 2)\n",
    "    ax.set_ylabel(\"property {:d}\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how this changes in time,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate(t):\n",
    "    i = ts.searchsorted(t)\n",
    "    rel_frac = rel_fracs[i]\n",
    "    \n",
    "    pdf = np.zeros(ys.shape + (n_prop,))\n",
    "    for dist, f, color, ls in zip(y_dists, rel_frac, species_colors, lines):\n",
    "        species_pdf = f * dist.pdf(ys[:, None])\n",
    "        pdf += species_pdf\n",
    "        for i, ax in enumerate(axes):\n",
    "            ls[i].set_data(ys, species_pdf[:, i])\n",
    "            \n",
    "    for i, ax in enumerate(axes):\n",
    "        totals[i].set_data(ys, pdf[:, i])\n",
    "        \n",
    "    n_species_sampled = np.random.multinomial(n_samples, rel_frac)\n",
    "    sample = np.concatenate(\n",
    "        [dist.rvs(size=(n, n_prop)) for dist, n in zip(y_dists, n_species_sampled)])\n",
    "    \n",
    "    artists = []\n",
    "    for i, hist in enumerate(histograms):\n",
    "        artists.extend(hist.update_data(sample[:, i]))\n",
    "        \n",
    "    for ax in axes:\n",
    "        ax.set_ylim(0, 2)\n",
    "        \n",
    "    return artists\n",
    "\n",
    "ani = animation.FuncAnimation(\n",
    "    fig, animate, np.linspace(ts[0], ts[-1], 100), repeat=False, blit=True)\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LotkaVolterra(object):\n",
    "    \n",
    "    def __init__(self, r, A, K, dists):\n",
    "        self.r = r\n",
    "        self.A = A\n",
    "        self.K = K\n",
    "        self.args = (r, A, K)\n",
    "        self.dists = dists\n",
    "        self.prop_shape = self.dists[0].mean().shape\n",
    "        \n",
    "    def odeint(self, x0, ts):\n",
    "        return odeint(lotka_volterra, x0, ts, args=self.args)\n",
    "    \n",
    "    def tau_leaping(self, x0, ts):\n",
    "        return tau_leaping(LV_birthdeath, x0, ts, args=self.args)\n",
    "    \n",
    "    def CLAint(self, x0, ts, cov0=None):\n",
    "        if cov0 is None:\n",
    "            cov0 = np.zeros_like(x0)\n",
    "        \n",
    "        K = self.K\n",
    "        x_hat, covs = CLAint(LV_CLA, x0/K, cov0, ts, args=self.args)\n",
    "        return x_hat * K, covs * K**2\n",
    "    \n",
    "    def sample_properties(self, xs, nsamples):\n",
    "        rel_fracs = xs / xs.sum(1, keepdims=True)\n",
    "        \n",
    "        samples = np.empty((len(xs), nsamples,) + self.prop_shape)\n",
    "        for i, rel_frac in enumerate(rel_fracs):\n",
    "            samples[i] = np.concatenate(\n",
    "                [dist.rvs(size=(n,) + self.prop_shape) for dist, n in \n",
    "                 zip(self.dists, np.random.multinomial(n_samples, rel_frac))])\n",
    "        \n",
    "        return samples\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv = LotkaVolterra(r, A, K, y_dists)\n",
    "\n",
    "x_tau = lv.tau_leaping(x0, ts)\n",
    "plt.plot(ts, x_tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_sample = np.linspace(10, 100, 5)\n",
    "samples = lv.sample_properties(xs[ts.searchsorted(t_sample)], nsamples=5000)\n",
    "\n",
    "f, axes = plt.subplots(5, figsize=(8,10), sharex=True)\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    for j in range(n_prop):\n",
    "        Histogram(samples[i, :, j], bins=100, density=True, ax=ax,\n",
    "                 facecolor=colors[4 + j], lw=0, alpha=0.3)\n",
    "        \n",
    "    ax.set_ylabel(\"time = {:.1f}\".format(t_sample[i]))\n",
    "    ax.set_ylim(0, 3)\n",
    "    \n",
    "ax.set_xlabel(\"properties\")\n",
    "f.tight_layout()\n",
    "f.subplots_adjust(hspace=0.03)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
